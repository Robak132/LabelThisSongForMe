{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuzDnIuJLEz2"
   },
   "source": [
    "# Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQXBbqGKG-U3",
    "outputId": "35962890-3ec3-4605-ba1b-a6a2dbf22f7b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File ‘/content/drive/MyDrive/data/mtat/mp3.zip.001’ already there; not retrieving.\n",
      "File ‘/content/drive/MyDrive/data/mtat/mp3.zip.002’ already there; not retrieving.\n",
      "File ‘/content/drive/MyDrive/data/mtat/mp3.zip.003’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://mirg.city.ac.uk/datasets/magnatagatune/mp3.zip.001 -O /content/drive/MyDrive/data/mtat/mp3.zip.001\n",
    "!wget -nc https://mirg.city.ac.uk/datasets/magnatagatune/mp3.zip.002 -O /content/drive/MyDrive/data/mtat/mp3.zip.002\n",
    "!wget -nc https://mirg.city.ac.uk/datasets/magnatagatune/mp3.zip.003 -O /content/drive/MyDrive/data/mtat/mp3.zip.003\n",
    "!if [ ! -f /content/drive/MyDrive/data/mtat/mp3_all.zip ]; then cat /content/drive/MyDrive/data/mtat/mp3.zip.* > /content/drive/MyDrive/data/mtat/mp3_all.zip; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-P_Nut8jmLb1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "464a79c8-9f3c-4ad9-fe91-aaf666ae322a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archive:  /content/drive/MyDrive/data/mtat/mp3_all.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of /content/drive/MyDrive/data/mtat/mp3_all.zip or\n",
      "        /content/drive/MyDrive/data/mtat/mp3_all.zip.zip, and cannot find /content/drive/MyDrive/data/mtat/mp3_all.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "!unzip -n /content/drive/MyDrive/data/mtat/mp3_all.zip -d /content/drive/MyDrive/data/mtat/mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "BdHmpyaACon8",
    "outputId": "f6f89bc6-9145-429f-a632-35edd6e6c4b5"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-f790d1f541a6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mProcessor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miterate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/content/drive/MyDrive/data\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/content/LabelThisSongForMe/src/data/make_features.py\u001B[0m in \u001B[0;36miterate\u001B[0;34m(self, data_path)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0miterate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_paths\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mfn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfiles\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m             \u001B[0mnpy_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnpy_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m'npy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/LabelThisSongForMe/src/data/make_features.py\u001B[0m in \u001B[0;36mget_paths\u001B[0;34m(self, data_path)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_paths\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfiles\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mglob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglob\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'mtat'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'mp3'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'*/*.mp3'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnpy_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'mtat'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'npy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnpy_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/glob.py\u001B[0m in \u001B[0;36mglob\u001B[0;34m(pathname, recursive)\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0mzero\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mmore\u001B[0m \u001B[0mdirectories\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0msubdirectories\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \"\"\"\n\u001B[0;32m---> 21\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miglob\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpathname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursive\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrecursive\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0miglob\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpathname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursive\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/glob.py\u001B[0m in \u001B[0;36m_iglob\u001B[0;34m(pathname, recursive, dironly)\u001B[0m\n\u001B[1;32m     72\u001B[0m         \u001B[0mglob_in_dir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_glob0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mdirname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdirs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 74\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mglob_in_dir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbasename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdironly\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     75\u001B[0m             \u001B[0;32myield\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/glob.py\u001B[0m in \u001B[0;36m_glob1\u001B[0;34m(dirname, pattern, dironly)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_glob1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpattern\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdironly\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 82\u001B[0;31m     \u001B[0mnames\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_iterdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdironly\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     83\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_ishidden\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpattern\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m         \u001B[0mnames\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnames\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0m_ishidden\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/glob.py\u001B[0m in \u001B[0;36m_iterdir\u001B[0;34m(dirname, dironly)\u001B[0m\n\u001B[1;32m    121\u001B[0m             \u001B[0mdirname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcurdir\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 123\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscandir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirname\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mit\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    124\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mentry\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mit\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import fire\n",
    "from src.data.make_features import Processor\n",
    "\n",
    "p = Processor()\n",
    "p.iterate(\"/content/drive/MyDrive/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhAv5T80pCRt"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.models.model import Musicnn\n",
    "from src.models.utilites import get_auc, to_var\n",
    "\n",
    "\n",
    "class Solver(object):\n",
    "    def __init__(self, data_loader, config):\n",
    "        # data loader\n",
    "        self.data_loader = data_loader\n",
    "        self.dataset = config.dataset\n",
    "        self.data_path = config.data_path\n",
    "\n",
    "        # training settings\n",
    "        self.n_epochs = config.n_epochs\n",
    "        self.lr = config.lr\n",
    "        self.use_tensorboard = config.use_tensorboard\n",
    "\n",
    "        # model path and step size\n",
    "        self.model_save_path = config.model_save_path\n",
    "        self.model_load_path = config.model_load_path\n",
    "        self.log_step = config.log_step\n",
    "        self.batch_size = config.batch_size\n",
    "        self.input_length = config.input_length\n",
    "\n",
    "        # cuda\n",
    "        self.is_cuda = torch.cuda.is_available()\n",
    "        print(f\"CUDA: {self.is_cuda}\")\n",
    "\n",
    "        # Build model\n",
    "        self.valid_list = np.load('split/mtat/valid.npy')\n",
    "        self.binary = np.load('split/mtat/binary.npy')\n",
    "        self.build_model()\n",
    "\n",
    "        # Tensorboard\n",
    "        self.writer = SummaryWriter()\n",
    "\n",
    "    def build_model(self):\n",
    "        # model\n",
    "        self.model = Musicnn(dataset=self.dataset)\n",
    "\n",
    "        # cuda\n",
    "        if self.is_cuda:\n",
    "            self.model.cuda()\n",
    "\n",
    "        # load pretrained model\n",
    "        if len(self.model_load_path) > 1:\n",
    "            self.load(self.model_load_path)\n",
    "\n",
    "        # loss function\n",
    "        self.loss_function = nn.BCELoss()\n",
    "\n",
    "        # optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), self.lr, weight_decay=1e-4)\n",
    "\n",
    "    def load(self, filename):\n",
    "        s = torch.load(filename)\n",
    "        if 'spec.mel_scale.fb' in s.keys():\n",
    "            self.model.spec.mel_scale.fb = s['spec.mel_scale.fb']\n",
    "        self.model.load_state_dict(s)\n",
    "\n",
    "    def train(self):\n",
    "        # Start training\n",
    "        start_t = time.time()\n",
    "        best_metric = 0\n",
    "        reconst_loss = self.loss_function\n",
    "\n",
    "        # Iterate\n",
    "        for epoch in range(self.n_epochs):\n",
    "            ctr = 0\n",
    "            loss = None\n",
    "            self.model = self.model.train()\n",
    "\n",
    "            for x, y in self.data_loader:\n",
    "                ctr += 1\n",
    "                # Forward\n",
    "                x = to_var(x)\n",
    "                y = to_var(y)\n",
    "                out = self.model(x)\n",
    "\n",
    "                # Backward\n",
    "                loss = reconst_loss(out, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Log\n",
    "                self.print_log(epoch, ctr, loss, start_t)\n",
    "\n",
    "            if loss is not None:\n",
    "                self.writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "\n",
    "            # validation\n",
    "            best_metric = self.validation(best_metric, epoch)\n",
    "\n",
    "        print(f\"{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Train finished. \"\n",
    "              f\"Elapsed: {datetime.timedelta(seconds=time.time() - start_t)}\")\n",
    "\n",
    "    def save(self, filename):\n",
    "        model = self.model.state_dict()\n",
    "        torch.save({'model': model}, filename)\n",
    "\n",
    "    def get_tensor(self, fn):\n",
    "        # load audio\n",
    "        npy_path = os.path.join(self.data_path, 'mtat', 'npy', fn.split('/')[1][:-3]) + 'npy'\n",
    "        raw = np.load(npy_path, mmap_mode='r')\n",
    "\n",
    "        # split chunk\n",
    "        length = len(raw)\n",
    "        hop = (length - self.input_length) // self.batch_size\n",
    "        x = torch.zeros(self.batch_size, self.input_length)\n",
    "        for i in range(self.batch_size):\n",
    "            x[i] = torch.Tensor(raw[i * hop:i * hop + self.input_length]).unsqueeze(0)\n",
    "        return x\n",
    "\n",
    "    def print_log(self, epoch, ctr, loss, start_t):\n",
    "        if ctr % self.log_step == 0:\n",
    "            print(\"[%s] Epoch [%d/%d] Iter [%d/%d] train loss: %.4f Elapsed: %s\" %\n",
    "                  (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                   epoch + 1, self.n_epochs, ctr, len(self.data_loader), loss.item(),\n",
    "                   datetime.timedelta(seconds=time.time() - start_t)))\n",
    "\n",
    "    def validation(self, best_metric, epoch):\n",
    "        roc_auc, pr_auc, loss = self.get_validation_score(epoch)\n",
    "        score = 1 - loss\n",
    "        if score > best_metric:\n",
    "            print('best model!')\n",
    "            best_metric = score\n",
    "            torch.save(self.model.state_dict(),\n",
    "                       os.path.join(self.model_save_path, 'best_model.pth'))\n",
    "        return best_metric\n",
    "\n",
    "    def get_validation_score(self, epoch):\n",
    "        self.model = self.model.eval()\n",
    "        est_array = []\n",
    "        gt_array = []\n",
    "        losses = []\n",
    "        reconst_loss = self.loss_function\n",
    "        index = 0\n",
    "        for line in tqdm.tqdm(self.valid_list):\n",
    "            ix, fn = line.split('\\t')\n",
    "\n",
    "            # load and split\n",
    "            x = self.get_tensor(fn)\n",
    "\n",
    "            # ground truth\n",
    "            ground_truth = self.binary[int(ix)]\n",
    "\n",
    "            # forward\n",
    "            x = to_var(x)\n",
    "            y = torch.tensor([ground_truth.astype('float32') for _ in range(self.batch_size)]).cuda()\n",
    "            out = self.model(x)\n",
    "            loss = reconst_loss(out, y)\n",
    "            losses.append(float(loss.data))\n",
    "            out = out.detach().cpu()\n",
    "\n",
    "            # estimate\n",
    "            estimated = np.array(out).mean(axis=0)\n",
    "            est_array.append(estimated)\n",
    "\n",
    "            gt_array.append(ground_truth)\n",
    "            index += 1\n",
    "\n",
    "        est_array, gt_array = np.array(est_array), np.array(gt_array)\n",
    "        loss = np.mean(losses)\n",
    "        print('loss: %.4f' % loss)\n",
    "\n",
    "        roc_auc, pr_auc = get_auc(est_array, gt_array)\n",
    "        self.writer.add_scalar('Loss/valid', loss, epoch)\n",
    "        self.writer.add_scalar('AUC/ROC', roc_auc, epoch)\n",
    "        self.writer.add_scalar('AUC/PR', pr_auc, epoch)\n",
    "        return roc_auc, pr_auc, loss\n"
   ],
   "metadata": {
    "id": "qbvl2D_U4CkS"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "bKVbr2i7pEC5",
    "outputId": "6d828d44-227f-4315-838b-3aa22295d13c"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-92d8a71c4c46>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmakedirs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_save_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m train_loader = get_audio_loader(config.data_path,\n\u001B[0m\u001B[1;32m     24\u001B[0m                                 \u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m                                 \u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'TRAIN'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/LabelThisSongForMe/src/models/loader.py\u001B[0m in \u001B[0;36mget_audio_loader\u001B[0;34m(root, batch_size, split, num_workers, input_length)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_audio_loader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'TRAIN'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_workers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_length\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m     data_loader = data.DataLoader(dataset=AudioFolder(root, split=split, input_length=input_length),\n\u001B[0m\u001B[1;32m     43\u001B[0m                                   \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m                                   \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/LabelThisSongForMe/src/models/loader.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, split, input_length)\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msplit\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minput_length\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_length\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_songlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbinary\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'split/mtat/binary.npy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/LabelThisSongForMe/src/models/loader.py\u001B[0m in \u001B[0;36mget_songlist\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_songlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'TRAIN'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'split/mtat/train.npy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'VALID'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'split/mtat/valid.npy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001B[0m\n\u001B[1;32m    438\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen_memmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmmap_mode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    439\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 440\u001B[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001B[0m\u001B[1;32m    441\u001B[0m                                          pickle_kwargs=pickle_kwargs)\n\u001B[1;32m    442\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py\u001B[0m in \u001B[0;36mread_array\u001B[0;34m(fp, allow_pickle, pickle_kwargs)\u001B[0m\n\u001B[1;32m    741\u001B[0m         \u001B[0;31m# The array contained Python objects. We need to unpickle the data.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    742\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mallow_pickle\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 743\u001B[0;31m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001B[0m\u001B[1;32m    744\u001B[0m                              \"allow_pickle=False\")\n\u001B[1;32m    745\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mpickle_kwargs\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "from src.models.loader import get_audio_loader\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.num_workers = 0\n",
    "        self.dataset = 'mtat'\n",
    "        self.n_epochs = 5\n",
    "        self.batch_size = 16\n",
    "        self.lr = 1e-4\n",
    "        self.use_tensorboard = 1\n",
    "        self.model_save_path = \"models\"\n",
    "        self.model_load_path = \"\"\n",
    "        self.data_path = '/content/drive/MyDrive/data'\n",
    "        self.log_step = 20\n",
    "        self.input_length = 3 * 16000\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "if not os.path.exists(config.model_save_path):\n",
    "    os.makedirs(config.model_save_path)\n",
    "\n",
    "train_loader = get_audio_loader(config.data_path,\n",
    "                                config.batch_size,\n",
    "                                split='TRAIN',\n",
    "                                input_length=config.input_length,\n",
    "                                num_workers=config.num_workers)\n",
    "solver = Solver(train_loader, config)\n",
    "solver.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
