{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.common import load_file_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def create_features(features_path, split_path):\n",
    "    try:\n",
    "        X_np = np.load(os.path.join(features_path, \"X.npy\"), allow_pickle=True)\n",
    "        Y_np = np.load(os.path.join(features_path, \"Y.npy\"), allow_pickle=True)\n",
    "    except OSError:\n",
    "        X = []\n",
    "        Y = []\n",
    "        data = load_file_lists([\n",
    "            os.path.join(split_path, \"train.npy\"),\n",
    "            os.path.join(split_path, \"valid.npy\"),\n",
    "            os.path.join(split_path, \"test.npy\")\n",
    "        ])\n",
    "        binary = {row[0]: row[1:] for row in np.load(os.path.join(split_path, \"binary.npy\"), allow_pickle=True)}\n",
    "        for idx, filename in data:\n",
    "            filename = os.path.join(\"../data/mtat/emb\", str(pathlib.Path(filename).with_suffix(\".npy\")))\n",
    "            file_data = np.load(filename, allow_pickle=True).flatten()\n",
    "            X.append(file_data)\n",
    "            Y.append(binary[int(idx)])\n",
    "        X_np = np.array(X)\n",
    "        Y_np = np.array(Y)\n",
    "        np.save(os.path.join(features_path, \"X.npy\"), X_np)\n",
    "        np.save(os.path.join(features_path, \"y.npy\"), Y_np)\n",
    "    return X_np, Y_np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 123456\n"
     ]
    }
   ],
   "source": [
    "set_seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "dataset_name = \"mtat-20\"\n",
    "split_path = \"../split\"\n",
    "features_path = \"../data/mtat/features/\"\n",
    "\n",
    "split_path = os.path.join(split_path, dataset_name)\n",
    "features_path = os.path.join(features_path, dataset_name)\n",
    "os.makedirs(split_path, exist_ok=True)\n",
    "os.makedirs(features_path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np, Y_np = create_features(features_path, split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_np, Y_np, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.79      0.72       987\n",
      "           1       0.73      0.70      0.71      1091\n",
      "           2       0.26      0.50      0.34       456\n",
      "           3       0.72      0.72      0.72       749\n",
      "           4       0.40      0.53      0.46       494\n",
      "           5       0.41      0.54      0.47       506\n",
      "           6       0.31      0.51      0.39       379\n",
      "           7       0.74      0.88      0.81       510\n",
      "           8       0.40      0.43      0.41       540\n",
      "           9       0.56      0.79      0.66       383\n",
      "          10       0.63      0.68      0.65       464\n",
      "          11       0.40      0.47      0.43       435\n",
      "          12       0.62      0.70      0.66       378\n",
      "          13       0.12      0.47      0.19       115\n",
      "          14       0.17      0.42      0.25       178\n",
      "          15       0.28      0.65      0.39       161\n",
      "          16       0.52      0.65      0.58       274\n",
      "          17       0.81      0.81      0.81       338\n",
      "          18       0.25      0.49      0.33       164\n",
      "          19       0.12      0.44      0.19        89\n",
      "\n",
      "   micro avg       0.49      0.65      0.55      8691\n",
      "   macro avg       0.46      0.61      0.51      8691\n",
      "weighted avg       0.54      0.65      0.58      8691\n",
      " samples avg       0.55      0.64      0.54      8691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model_filename_path = os.path.join(\"../models\", model.__class__.__name__)\n",
    "os.makedirs(model_filename_path, exist_ok=True)\n",
    "model_filename = os.path.join(model_filename_path, f\"{dataset_name}.bin\")\n",
    "pickle.dump(model, open(model_filename, 'wb+'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "dataset_name = \"mtat-10\"\n",
    "split_path = \"../split\"\n",
    "features_path = \"../data/mtat/features/\"\n",
    "\n",
    "split_path = os.path.join(split_path, dataset_name)\n",
    "features_path = os.path.join(features_path, dataset_name)\n",
    "os.makedirs(split_path, exist_ok=True)\n",
    "os.makedirs(features_path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "X_np, Y_np = create_features(features_path, split_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_np, Y_np, random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.77      1043\n",
      "           1       0.80      0.75      0.77      1166\n",
      "           2       0.41      0.64      0.50       583\n",
      "           3       0.77      0.74      0.75       771\n",
      "           4       0.51      0.59      0.55       592\n",
      "           5       0.45      0.58      0.50       492\n",
      "           6       0.40      0.54      0.46       461\n",
      "           7       0.79      0.87      0.83       499\n",
      "           8       0.44      0.46      0.45       562\n",
      "           9       0.54      0.83      0.66       347\n",
      "\n",
      "   micro avg       0.60      0.70      0.65      6516\n",
      "   macro avg       0.58      0.68      0.62      6516\n",
      "weighted avg       0.62      0.70      0.65      6516\n",
      " samples avg       0.65      0.70      0.63      6516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "model_filename_path = os.path.join(\"../models\", model.__class__.__name__)\n",
    "os.makedirs(model_filename_path, exist_ok=True)\n",
    "model_filename = os.path.join(model_filename_path, f\"{dataset_name}.bin\")\n",
    "pickle.dump(model, open(model_filename, 'wb+'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "dataset_name = \"mtat\"\n",
    "split_path = \"../split\"\n",
    "features_path = \"../data/mtat/features/\"\n",
    "\n",
    "split_path = os.path.join(split_path, dataset_name)\n",
    "features_path = os.path.join(features_path, dataset_name)\n",
    "os.makedirs(split_path, exist_ok=True)\n",
    "os.makedirs(features_path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "X_np, Y_np = create_features(features_path, split_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_np, Y_np, random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.78      0.71       990\n",
      "           1       0.70      0.67      0.68      1093\n",
      "           2       0.24      0.48      0.32       451\n",
      "           3       0.71      0.69      0.70       761\n",
      "           4       0.42      0.54      0.47       521\n",
      "           5       0.38      0.56      0.45       438\n",
      "           6       0.30      0.55      0.39       360\n",
      "           7       0.73      0.81      0.77       516\n",
      "           8       0.38      0.44      0.41       489\n",
      "           9       0.54      0.80      0.64       351\n",
      "          10       0.56      0.61      0.58       474\n",
      "          11       0.38      0.45      0.41       411\n",
      "          12       0.63      0.73      0.67       385\n",
      "          13       0.16      0.53      0.25       135\n",
      "          14       0.14      0.36      0.21       187\n",
      "          15       0.28      0.59      0.38       172\n",
      "          16       0.56      0.64      0.60       294\n",
      "          17       0.74      0.74      0.74       306\n",
      "          18       0.18      0.44      0.25       128\n",
      "          19       0.08      0.34      0.13        70\n",
      "          20       0.05      0.31      0.08        48\n",
      "          21       0.00      0.03      0.01        30\n",
      "          22       0.71      0.82      0.76       233\n",
      "          23       0.27      0.41      0.32       177\n",
      "          24       0.10      0.38      0.16        68\n",
      "          25       0.63      0.74      0.68       213\n",
      "          26       0.15      0.39      0.22        90\n",
      "          27       0.10      0.39      0.16        61\n",
      "          28       0.00      0.10      0.01        10\n",
      "          29       0.15      0.39      0.21        95\n",
      "          30       0.03      0.20      0.06        45\n",
      "          31       0.58      0.80      0.67       171\n",
      "          32       0.08      0.25      0.12        63\n",
      "          33       0.07      0.39      0.12        33\n",
      "          34       0.05      0.21      0.08        38\n",
      "          35       0.71      0.75      0.73       156\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.03      0.16      0.05        32\n",
      "          38       0.32      0.37      0.34       128\n",
      "          39       0.05      0.25      0.09        32\n",
      "          40       0.05      0.45      0.09        20\n",
      "          41       0.07      0.26      0.11        38\n",
      "          42       0.28      0.69      0.40        70\n",
      "          43       0.57      0.78      0.66       101\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.01      0.12      0.01         8\n",
      "          46       0.27      0.55      0.36        73\n",
      "          47       0.03      0.50      0.05         8\n",
      "          48       0.52      0.53      0.53       116\n",
      "          49       0.61      0.60      0.61       111\n",
      "\n",
      "   micro avg       0.38      0.61      0.47     10809\n",
      "   macro avg       0.31      0.47      0.35     10809\n",
      "weighted avg       0.50      0.61      0.54     10809\n",
      " samples avg       0.46      0.59      0.46     10809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "model_filename_path = os.path.join(\"../models\", model.__class__.__name__)\n",
    "os.makedirs(model_filename_path, exist_ok=True)\n",
    "model_filename = os.path.join(model_filename_path, f\"{dataset_name}.bin\")\n",
    "pickle.dump(model, open(model_filename, 'wb+'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"../models/KNeighborsClassifier/mtat.bin\", 'rb'))\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
