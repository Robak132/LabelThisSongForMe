{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/kubar/Documents/Sem7/labelthissongforme'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from components.common import load_file_lists\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/kubar/Documents/Sem7/labelthissongforme\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_path = \"split/mtat-20/\"\n",
    "os.makedirs(split_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 123456\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = OpenL3PreProcessor(input_path=\"../data/mtat/mp3\",\n",
    "#                        output_path=\"../data/mtat/emb\",\n",
    "#                        suffix=\"npy\")\n",
    "# # print(load_file_lists([\"../split/mtat/train.npy\", \"../split/mtat/valid.npy\", \"../split/mtat/test.npy\"])[:, 1])\n",
    "data = load_file_lists([\n",
    "    os.path.join(split_path, \"train.npy\"),\n",
    "    os.path.join(split_path, \"valid.npy\"),\n",
    "    os.path.join(split_path, \"test.npy\")\n",
    "])\n",
    "# p.run(files=data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['guitar', 'classical', 'slow', 'techno', 'strings', 'drums',\n",
       "       'electronic', 'rock', 'fast', 'piano', 'ambient', 'beat', 'violin',\n",
       "       'vocal', 'synth', 'female', 'indian', 'opera', 'male', 'singing'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary = {row[0]: row[1:] for row in np.load(os.path.join(split_path, \"binary.npy\"), allow_pickle=True)}\n",
    "tags = np.load(os.path.join(split_path, \"tags.npy\"), allow_pickle=True)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for idx, filename in data:\n",
    "    filename = os.path.join(\"data/mtat/emb\", str(pathlib.Path(filename).with_suffix(\".npy\")))\n",
    "    file_data = np.load(filename, allow_pickle=True).flatten()\n",
    "    X.append(file_data)\n",
    "    Y.append(binary[int(idx)])\n",
    "X_np = np.array(X)\n",
    "np.save(\"X.npy\", X_np)\n",
    "Y_np = np.array(Y)\n",
    "np.save(\"y.npy\", Y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6140246 , 1.8475785 , 4.3649316 , ..., 1.1230563 , 3.333457  ,\n",
       "        2.867814  ],\n",
       "       [2.4309678 , 2.4298744 , 2.9125767 , ..., 1.5540198 , 3.5779722 ,\n",
       "        3.57896   ],\n",
       "       [2.5092711 , 2.2790258 , 2.4283175 , ..., 0.48853248, 3.4483852 ,\n",
       "        2.2871022 ],\n",
       "       ...,\n",
       "       [2.4309678 , 2.2870908 , 3.9133983 , ..., 2.0478022 , 3.410993  ,\n",
       "        3.0003796 ],\n",
       "       [2.4309678 , 2.036916  , 3.4007561 , ..., 1.6041538 , 3.2292883 ,\n",
       "        3.3360808 ],\n",
       "       [2.4309678 , 2.7142615 , 2.9608872 , ..., 1.4507025 , 4.896281  ,\n",
       "        3.2105606 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np = np.load(\"X.npy\", allow_pickle=True)\n",
    "X_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_np = np.load(\"Y.npy\", allow_pickle=True)\n",
    "Y_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_np, Y_np, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.92      0.62       612\n",
      "           1       0.59      0.78      0.67       785\n",
      "           2       0.07      0.61      0.13       101\n",
      "           3       0.54      0.83      0.65       487\n",
      "           4       0.14      0.60      0.22       149\n",
      "           5       0.11      0.80      0.19        88\n",
      "           6       0.07      0.57      0.13        81\n",
      "           7       0.57      0.98      0.72       353\n",
      "           8       0.08      0.66      0.14        68\n",
      "           9       0.35      1.00      0.51       184\n",
      "          10       0.32      0.90      0.47       176\n",
      "          11       0.15      0.71      0.24       105\n",
      "          12       0.36      0.78      0.49       195\n",
      "          13       0.01      0.75      0.01         4\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.01      1.00      0.02         4\n",
      "          17       0.39      0.85      0.53       154\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.25      0.83      0.39      3547\n",
      "   macro avg       0.21      0.64      0.29      3547\n",
      "weighted avg       0.43      0.83      0.55      3547\n",
      " samples avg       0.31      0.46      0.34      3547\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robak/.virtualenvs/labelthissongforme/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/robak/.virtualenvs/labelthissongforme/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=20,\n",
    "                             max_features='sqrt',\n",
    "                             n_jobs=4,\n",
    "                             random_state=1,\n",
    "                             warm_start=True)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.51      0.52      1222\n",
      "           1       0.55      0.53      0.54      1080\n",
      "           2       0.28      0.28      0.28       894\n",
      "           3       0.54      0.55      0.55       730\n",
      "           4       0.37      0.36      0.37       687\n",
      "           5       0.29      0.30      0.29       636\n",
      "           6       0.32      0.31      0.32       648\n",
      "           7       0.56      0.57      0.56       596\n",
      "           8       0.26      0.26      0.26       566\n",
      "           9       0.39      0.43      0.41       478\n",
      "          10       0.39      0.40      0.39       484\n",
      "          11       0.29      0.35      0.32       433\n",
      "          12       0.43      0.40      0.41       448\n",
      "          13       0.23      0.21      0.22       495\n",
      "          14       0.18      0.18      0.18       411\n",
      "          15       0.20      0.19      0.19       384\n",
      "          16       0.20      0.20      0.20       351\n",
      "          17       0.52      0.51      0.51       345\n",
      "          18       0.20      0.20      0.20       333\n",
      "          19       0.15      0.14      0.14       342\n",
      "\n",
      "   micro avg       0.37      0.37      0.37     11563\n",
      "   macro avg       0.34      0.34      0.34     11563\n",
      "weighted avg       0.37      0.37      0.37     11563\n",
      " samples avg       0.41      0.40      0.36     11563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robak/.virtualenvs/labelthissongforme/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=20,\n",
    "                               max_features='sqrt',\n",
    "                               random_state=1)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.79      0.72       987\n",
      "           1       0.73      0.70      0.71      1091\n",
      "           2       0.26      0.50      0.34       456\n",
      "           3       0.72      0.72      0.72       749\n",
      "           4       0.40      0.53      0.46       494\n",
      "           5       0.41      0.54      0.47       506\n",
      "           6       0.31      0.51      0.39       379\n",
      "           7       0.74      0.88      0.81       510\n",
      "           8       0.40      0.43      0.41       540\n",
      "           9       0.56      0.79      0.66       383\n",
      "          10       0.63      0.68      0.65       464\n",
      "          11       0.40      0.47      0.43       435\n",
      "          12       0.62      0.70      0.66       378\n",
      "          13       0.12      0.47      0.19       115\n",
      "          14       0.17      0.42      0.25       178\n",
      "          15       0.28      0.65      0.39       161\n",
      "          16       0.52      0.65      0.58       274\n",
      "          17       0.81      0.81      0.81       338\n",
      "          18       0.25      0.49      0.33       164\n",
      "          19       0.12      0.44      0.19        89\n",
      "\n",
      "   micro avg       0.49      0.65      0.55      8691\n",
      "   macro avg       0.46      0.61      0.51      8691\n",
      "weighted avg       0.54      0.65      0.58      8691\n",
      " samples avg       0.55      0.64      0.54      8691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robak/.virtualenvs/labelthissongforme/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.96      0.04        24\n",
      "           1       0.00      0.11      0.00         9\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.09      0.85      0.16        75\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.50      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.01      1.00      0.01         4\n",
      "          10       0.00      1.00      0.01         2\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.01      0.79      0.02       121\n",
      "   macro avg       0.01      0.22      0.01       121\n",
      "weighted avg       0.06      0.79      0.10       121\n",
      " samples avg       0.01      0.02      0.01       121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robak/.virtualenvs/labelthissongforme/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/robak/.virtualenvs/labelthissongforme/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RadiusNeighborsClassifier(radius=100.)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "single_output_model = LogisticRegression(solver='saga',\n",
    "                                         max_iter=3000,\n",
    "                                         random_state=1)\n",
    "model = ClassifierChain(single_output_model, random_state=1)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "single_output_model = LogisticRegression(solver='saga',\n",
    "                                         max_iter=3000,\n",
    "                                         random_state=1)\n",
    "model = MultiOutputClassifier(single_output_model, n_jobs=4)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "single_output_model = SVC(max_iter=3000, random_state=1)\n",
    "model = MultiOutputClassifier(single_output_model, n_jobs=4)\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
